{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ταξινόμηση ιδιοτήτων-προτάσεων σε συστήματα οργάνων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import spacy\n",
    "import el_core_news_md\n",
    "nlp = el_core_news_md.load()\n",
    "from greek_stemmer import GreekStemmer\n",
    "stemmer = GreekStemmer()\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "total_stop_words = (nlp.Defaults.stop_words).union(set(stopwords.words('greek')))\n",
    "total_stop_words = total_stop_words.union({'ή', 'μόνον'})\n",
    "total_puncts = string.punctuation + '«»–“”\\xa0‘•…●\\uf0b7◗♥.'\n",
    "total_stop_words = list(total_stop_words) + list(string.punctuation)\n",
    "#total_stop_words += [stemming(word) for word in total_stop_words]\n",
    "stop_words = set(total_stop_words)\n",
    "tokenized_stop_words = nltk.word_tokenize(' '.join(total_stop_words))\n",
    "\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        nltk.download('punkt', quiet=True, raise_on_error=True)\n",
    "        self.stemmer = GreekStemmer()\n",
    "        \n",
    "    def _stem(self, token):\n",
    "        if (token in stop_words):\n",
    "            return token\n",
    "        return self.stemmer.stem((removing_accents(token)).upper())\n",
    "        \n",
    "    def __call__(self, line):\n",
    "        tokens = nltk.word_tokenize(line)\n",
    "        tokens = filter_punctuation(list(tokens))\n",
    "        tokens = group_numbers(tokens)\n",
    "        tokens = (self._stem(token) for token in tokens)\n",
    "        return tokens\n",
    "\n",
    "\n",
    "\n",
    "def data_preparation(data_filename, target, test_size=0.25, stopwords=tokenized_stop_words, max_frequency=0.5, min_frequency=6, \n",
    "                     imbalanced=False):\n",
    "    df_texts = pd.read_csv(data_filename, index_col=None)\n",
    "    df_texts = df_texts.dropna(axis=0, subset = [target])\n",
    "    df_texts[target] = df_texts[target].astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_texts['Sentence'], df_texts[target], test_size=test_size, \n",
    "                                                        random_state=10)\n",
    "    vectorizer = TfidfVectorizer(max_df=max_frequency, min_df=min_frequency, stop_words=stopwords, tokenizer=Tokenizer())\n",
    "    X_train_tf_idf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tf_idf = vectorizer.transform(X_test)\n",
    "    if imbalanced:\n",
    "        ros = RandomOverSampler(random_state=0)\n",
    "        X_train_tf_idf, y_train = ros.fit_sample(X_train_tf_idf, y_train)\n",
    "    \n",
    "    return X_train_tf_idf, X_test_tf_idf, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "def filter_punctuation(words):\n",
    "    filtered_words = []\n",
    "    for word in words:\n",
    "        pun = []\n",
    "        for letter in word:\n",
    "            pun.append(letter in total_puncts)\n",
    "\n",
    "        if not all(pun):\n",
    "            word = word.strip(total_puncts)\n",
    "            \n",
    "            if (len(word)>3):\n",
    "                for punct in total_puncts:\n",
    "                    word = word.replace(punct, ' ')\n",
    "            else:\n",
    "                for punct in total_puncts:\n",
    "                    word = word.replace(punct, '')\n",
    "                    \n",
    "            tokens = nltk.word_tokenize(word)\n",
    "            \n",
    "            for token in tokens:\n",
    "                filtered_words.append(token)\n",
    "                \n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "\n",
    "def group_numbers(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if re.fullmatch(r'[0-9]+', word) != None :\n",
    "            if int(word) >= 1800 and int(word) <= 2020:\n",
    "                word = '2000'\n",
    "            else:\n",
    "                word = '1'\n",
    "        new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "\n",
    "def removing_accents(word):\n",
    "    \"\"\"\n",
    "    Removes accents from a given word.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        the word from which we want to remove the accents\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        the word without accents\n",
    "    \"\"\"\n",
    "    return (word.replace('ά', 'α').replace('έ', 'ε').replace('ή', 'η').replace('ί', 'ι').replace('ό', 'ο').replace('ύ', 'υ')\n",
    "            .replace('ώ', 'ω').replace('ϊ', 'ι').replace('ϋ', 'υ').replace('ΐ', 'ι').replace('ΰ', 'υ'))\n",
    "\n",
    "\n",
    "\n",
    "def stemming(word):\n",
    "    \"\"\"\n",
    "    Implements stemming for a given word.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        the word that is about to be stemmed\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        the stem of the given word at uppercase letters\n",
    "    \"\"\"\n",
    "    return stemmer.stem((removing_accents(word)).upper())\n",
    "\n",
    "\n",
    "\n",
    "def classification(dataset_filename, target_column, classifier, test_size=0.25, stopwords=tokenized_stop_words, \n",
    "                   max_frequency=0.5, min_frequency=6, imbalanced=False):    \n",
    "    X_train, X_test, y_train, y_test = data_preparation(dataset_filename, target_column, imbalanced=imbalanced)\n",
    "    \n",
    "    switcher = {'svc': SVC(), 'knn': KNeighborsClassifier(n_neighbors=20), 'naive_bayes': GaussianNB(), \n",
    "                'decision_tree': DecisionTreeClassifier(), 'random_forest': RandomForestClassifier()} \n",
    "    bin_clf = switcher.get(classifier)\n",
    "    \n",
    "    clf = OneVsRestClassifier(bin_clf).fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    \n",
    "    results = list(zip(X_test, y_test, preds))\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    return results, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Πρώτα δοκιμάζουμε σύμφωνα με το απλούτσερο annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res1, accuracy1 = classification('../data/properties.csv', 'Class1', 'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920477137176938"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Έπειτα, δοκιμάζουμε το πιο μεγάλο annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res2, accuracy2 = classification('../data/properties.csv', 'Class2', 'svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8609098811938568"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res3, accuracy3 = classification('../data/properties.csv', 'Class2', 'knn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8232396406838598"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res4, accuracy4 = classification('../data/properties.csv', 'Class2', 'decision_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777166038829325"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res5, accuracy5 = classification('../data/properties.csv', 'Class2', 'random_forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9235004346566212"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
